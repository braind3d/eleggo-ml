{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library setups and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# import wget\n",
    "# import py7zr\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "# from pyunpack import Archive\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow_core._api.v2.config' has no attribute 'list_physical_devices'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3f8719ff6c39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_physical_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GPU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow_core._api.v2.config' has no attribute 'list_physical_devices'"
     ]
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_DOWNLOADED_SET = True\n",
    "DOWNLOADED_SET_URL = 'https://hkinsley.com/static/downloads/bci/model_data_v2.7z'\n",
    "DATA_DIR = 'data/mask-iv-openbci' if USE_DOWNLOADED_SET else 'data/personal'\n",
    "LABELS = {\"left\": [1, 0, 0], \"none\": [0, 1, 0], \"right\": [0, 0, 1]}\n",
    "INPUT_SHAPE=(-1, 8, 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.exists(DATA_DIR):\n",
    "#     wget.download(DOWNLOADED_SET_URL, os.path.join(path, '../mask-iv-openbci.7z'))\n",
    "#     with py7zr.SevenZipFile(os.path.join(DATA_DIR, '../mask-iv-openbci.7z'), mode='r') as z:\n",
    "#         z.extractall(path)\n",
    "    # TODO: Automatically move 'data' and 'validation_data' one 1 level up on downloaded oh..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(is_validation_data):\n",
    "    dataset = []\n",
    "    path = os.path.join(DATA_DIR)\n",
    "    subdir = 'validation_data/' if is_validation_data else 'data/'\n",
    "\n",
    "    for label in LABELS:\n",
    "        label_dir = os.path.join(path, subdir, label)\n",
    "        for FILE in os.listdir(label_dir):\n",
    "            if USE_DOWNLOADED_SET:\n",
    "                ffts = np.load(os.path.join(DATA_DIR, subdir, label, FILE))\n",
    "                for fft_data in ffts:\n",
    "                    dataset.append([fft_data[:8], LABELS[label]])\n",
    "            else:\n",
    "                fft_data = np.load(os.path.join(DATA_DIR, FILE))\n",
    "                dataset.append([fft_data[:8], label])\n",
    "        \n",
    "        random.shuffle(dataset)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = generate_dataset(False)\n",
    "validation = generate_dataset(True)\n",
    "\n",
    "train_x = []\n",
    "train_y = []\n",
    "for x, y in training:\n",
    "    train_x.append(x)\n",
    "    train_y.append(y)\n",
    "    \n",
    "val_x = []\n",
    "val_y = []\n",
    "for x, y in validation:\n",
    "    val_x.append(x)\n",
    "    val_y.append(y)\n",
    "\n",
    "train_x = np.array(train_x).reshape(INPUT_SHAPE)\n",
    "val_x = np.array(val_x).reshape(INPUT_SHAPE)\n",
    "\n",
    "train_y = np.array(train_y)\n",
    "val_y = np.array(val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv1D(32, (2), activation='relu', input_shape=train_x.shape[1:], padding='same'),\n",
    "    MaxPooling1D(pool_size=(2),\n",
    "    Conv1D(128, (2), activation='relu', padding='same'),\n",
    "    MaxPooling1D(pool_size=(2)),\n",
    "    Conv1D(64, (4), activation='relu', padding='same'),\n",
    "    MaxPooling1D(pool_size=(2)),\n",
    "    Dropout(0.4),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu', kernel_regularizer='l1'),\n",
    "    Dense(3, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 8, 256)            30976     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 4, 128)            65664     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 2, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 2, 64)             32832     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 138,179\n",
      "Trainable params: 138,179\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 284625 samples, validate on 35250 samples\n",
      "Epoch 1/30\n",
      "284625/284625 [==============================] - 9s 32us/sample - loss: 7.2915 - accuracy: 0.3998 - val_loss: 6.3261 - val_accuracy: 0.3675\n",
      "Epoch 2/30\n",
      "284625/284625 [==============================] - 9s 30us/sample - loss: 5.3501 - accuracy: 0.4653 - val_loss: 4.5870 - val_accuracy: 0.4107\n",
      "Epoch 3/30\n",
      "284625/284625 [==============================] - 9s 30us/sample - loss: 3.7630 - accuracy: 0.4981 - val_loss: 3.1738 - val_accuracy: 0.4290\n",
      "Epoch 4/30\n",
      "284625/284625 [==============================] - 9s 31us/sample - loss: 2.5284 - accuracy: 0.5206 - val_loss: 2.1221 - val_accuracy: 0.4297\n",
      "Epoch 5/30\n",
      "284625/284625 [==============================] - 9s 31us/sample - loss: 1.6583 - accuracy: 0.5366 - val_loss: 1.4436 - val_accuracy: 0.4469\n",
      "Epoch 6/30\n",
      "284625/284625 [==============================] - 9s 31us/sample - loss: 1.1574 - accuracy: 0.5457 - val_loss: 1.1382 - val_accuracy: 0.4433\n",
      "Epoch 7/30\n",
      "284625/284625 [==============================] - 9s 31us/sample - loss: 0.9887 - accuracy: 0.5522 - val_loss: 1.1020 - val_accuracy: 0.4277\n",
      "Epoch 8/30\n",
      "284625/284625 [==============================] - 9s 32us/sample - loss: 0.9507 - accuracy: 0.5634 - val_loss: 1.1155 - val_accuracy: 0.4286\n",
      "Epoch 9/30\n",
      "284625/284625 [==============================] - 9s 32us/sample - loss: 0.9221 - accuracy: 0.5789 - val_loss: 1.1334 - val_accuracy: 0.4254\n",
      "Epoch 10/30\n",
      "284625/284625 [==============================] - 9s 31us/sample - loss: 0.8956 - accuracy: 0.5930 - val_loss: 1.1824 - val_accuracy: 0.4172\n",
      "Epoch 11/30\n",
      "284625/284625 [==============================] - 9s 31us/sample - loss: 0.8711 - accuracy: 0.6074 - val_loss: 1.2161 - val_accuracy: 0.4064\n",
      "Epoch 12/30\n",
      "284625/284625 [==============================] - 9s 31us/sample - loss: 0.8466 - accuracy: 0.6217 - val_loss: 1.2500 - val_accuracy: 0.4042\n",
      "Epoch 13/30\n",
      "284625/284625 [==============================] - 9s 31us/sample - loss: 0.8247 - accuracy: 0.6350 - val_loss: 1.2860 - val_accuracy: 0.4029\n",
      "Epoch 14/30\n",
      "284625/284625 [==============================] - 9s 31us/sample - loss: 0.8010 - accuracy: 0.6492 - val_loss: 1.3157 - val_accuracy: 0.4119\n",
      "Epoch 15/30\n",
      "284625/284625 [==============================] - 9s 32us/sample - loss: 0.7835 - accuracy: 0.6593 - val_loss: 1.3792 - val_accuracy: 0.4025\n",
      "Epoch 16/30\n",
      "284625/284625 [==============================] - 9s 32us/sample - loss: 0.7623 - accuracy: 0.6721 - val_loss: 1.3713 - val_accuracy: 0.4071\n",
      "Epoch 17/30\n",
      "123904/284625 [============>.................] - ETA: 4s - loss: 0.7481 - accuracy: 0.6797"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x, train_y, epochs=30, batch_size=1024, validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = plt.figure(1)\n",
    "history_loss = history.history['loss']\n",
    "history_val_loss = history.history['val_loss']\n",
    "epochs = range(len(history_loss))\n",
    "\n",
    "plt.plot(epochs, history_loss, 'ko', label='Training loss')\n",
    "plt.plot(epochs, history_val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "loss = plt.figure(2)\n",
    "history_acc = history.history['accuracy']\n",
    "history_val_acc = history.history['val_accuracy']\n",
    "epochs = range(len(history_loss))\n",
    "\n",
    "plt.plot(epochs, history_acc, 'ko', label='Training acc')\n",
    "plt.plot(epochs, history_val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
